{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70ab82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39598d14",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a67c6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_cs_2023 = pd.read_excel(\"../Data/Global Case Sales 2023.xlsx\") # (572,887  ,  20)\n",
    "master_facility = pd.read_excel(\"../Data/Master Facility List.xlsx\") # (7,126  ,  92)\n",
    "assurance_volume = pd.read_csv(\"../Data/QSET_ASSURANCE_PROD_VOL_EXPORT.csv\") # (29,177  ,  5)\n",
    "\n",
    "water_wwd = pd.read_excel(\"../Data/Water & WWD Comments.xlsx\")\n",
    "water_wwd = water_wwd[water_wwd['Indicator'] == 'Total Wastewater Discharged (kL) [kL]']  # (9,254  ,  9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a37b1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"Indicator_Name\", \"Code\", \"Entity_Name\", \n",
    "    \"Facility_ID\", \"Reporting_Period\", \"Answer\"\n",
    "]\n",
    "\n",
    "numeric_input_ind = pd.read_csv(\"../Data/Monthly Numeric Indicator.csv\", encoding='utf-16', sep='\\t', header=0, names=column_names) # (197,418  ,  6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b4b2fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"Reporting_Period\", \"Entity_Name\", \"Code\", \"Indicator_Name\", \"Answer\", \"Unit\", \n",
    "    \"Help_Text\", \"Comments\", \"Frequency\", \"FolderPath\", \"Ord\"\n",
    "]\n",
    "text_input_ind = pd.read_csv(\"../Data/Monthly Text Input Indicator.csv\", encoding='ISO-8859-1',header=0, names=column_names) # (70,917  ,  11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452c1a55",
   "metadata": {},
   "source": [
    "### Task 1: Text Input\n",
    "- Check to see if answers for the same indicator switches one month to next, if yes outlier\n",
    "- If answer is missing, outlier\n",
    "\n",
    "- Columns to keep: Facility_ID, Facility_Name, Bottler, OU, Reporting_Period, Detection_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6ad9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Facility_ID by splitting FolderPath at '>', taking the last part, and trimming whitespace.\n",
    "text_input_ind['Facility_ID'] = text_input_ind['FolderPath'].apply(lambda x: x.split('>')[-1].strip())\n",
    "\n",
    "# Convert Facility_ID to a numeric type, coercing errors to NaN, and then change to int64.\n",
    "text_input_ind['Facility_ID'] = pd.to_numeric(text_input_ind['Facility_ID'], errors='coerce').astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45c2a5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'Answer': 26106\n"
     ]
    }
   ],
   "source": [
    "# Count the number of missing values in the \"Answer\" column\n",
    "missing_count_answer = text_input_ind[\"Answer\"].isnull().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of missing values in 'Answer': {missing_count_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0351d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a merge based on Facility_ID\n",
    "text_input_ind = text_input_ind.merge(\n",
    "    master_facility[['FACILITY_ID', 'FACILITY_NAME', 'BTLR_NAME_ISSCOM', 'BUNAME_BU']],\n",
    "    left_on='Facility_ID',\n",
    "    right_on='FACILITY_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# # Drop the extra FACILITY_ID column after merge to avoid duplication\n",
    "# text_input_ind = text_input_ind.drop(columns=['FACILITY_ID_x'])\n",
    "\n",
    "# # Rename columns to match the desired names\n",
    "# text_input_ind = text_input_ind.rename(columns={'FACILITY_ID_y': 'Facility_ID', 'FACILITY_NAME': 'Facility_Name'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "637a247b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70917, 16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b29a4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'Answer': 26106\n"
     ]
    }
   ],
   "source": [
    "# Count the number of missing values in the \"Answer\" column\n",
    "missing_count_answer = text_input_ind[\"Answer\"].isnull().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of missing values in 'Answer': {missing_count_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c11424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the relevant columns\n",
    "cols_to_keep = [\"BUNAME_BU\", \"Reporting_Period\", \"Facility_ID\", \"FACILITY_NAME\", \"BTLR_NAME_ISSCOM\", \"Indicator_Name\", \"Answer\"]\n",
    "text_input_ind = text_input_ind[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e3dae2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'Answer': 26106\n"
     ]
    }
   ],
   "source": [
    "# Count the number of missing values in the \"Answer\" column\n",
    "missing_count_answer = text_input_ind[\"Answer\"].isnull().sum()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of missing values in 'Answer': {missing_count_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b296a07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70917, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_changes(df):\n",
    "    \"\"\"\n",
    "    Process a DataFrame to identify anomalies in answers for specific indicators within facilities over time.\n",
    "\n",
    "    This function cleans business unit names, sorts data by facility and indicators, flags entries where answers \n",
    "    have changed or are missing, and updates the DataFrame with detection results and details. It returns both \n",
    "    the processed complete DataFrame and a subset containing flagged entries.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame containing columns such as 'BUNAME_BU', 'Reporting_Period', 'Facility_ID', 'Indicator_Name', \n",
    "        'Answer', and other relevant fields necessary for detection.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    df : pandas.DataFrame\n",
    "        The complete DataFrame updated with flags and detection details for each entry.\n",
    "\n",
    "    flagged_df : pandas.DataFrame\n",
    "        A subset of the DataFrame containing only flagged entries with columns including 'BUNAME_BU', 'Reporting_Period', \n",
    "        'Facility_ID', 'Indicator_Name', 'Detection_Result', and 'Detection_Details'.\n",
    "\n",
    "    datasets : dict of pandas.DataFrame\n",
    "        A dictionary with keys representing BUNAME values from the original data where:\n",
    "        - \"{buname}_full_dataset\": Full dataset for the BU.\n",
    "        - \"{buname}_flagged_dataset\": Flagged subset for the BU.\n",
    "\n",
    "    Notes:\n",
    "    -----\n",
    "    - The function does not separate files by `BUNAME_BU`; it organizes data and detection logic.\n",
    "    - 'Reporting_Period' needs to be in a format suitable for conversion to datetime objects for accurate sorting.\n",
    "    - Anomalies in the 'Answer' include cases where the answer changes from the previous period or is missing.\n",
    "\n",
    "    Example:\n",
    "    -------\n",
    "    df, flagged_df, datasets = detect_changes(input_dataframe)\n",
    "    \"\"\"    \n",
    "\n",
    "    # Remove suffix \"BU\" from BUNAME_BU values\n",
    "    df['BUNAME_BU'] = df['BUNAME_BU'].str.replace(r'\\s*BU$', '', regex=True)\n",
    "\n",
    "    # Ensure 'Reporting_Period' is a datetime object for sorting\n",
    "    df['Reporting_Period'] = pd.to_datetime(df['Reporting_Period'], format='%m/%d/%Y')\n",
    "\n",
    "    # Sort the DataFrame by 'Facility_ID', 'Indicator_Name', and 'Reporting_Period'\n",
    "    df.sort_values(by=['Facility_ID', 'Indicator_Name', 'Reporting_Period'], inplace=True)\n",
    "\n",
    "    # Initialize 'Flag' column with default value 0\n",
    "    df['Flag'] = 0\n",
    "    \n",
    "    # Define a function to flag changes and missing answers\n",
    "    def flag_changes_with_initial_check(group):\n",
    "        shifted = group['Answer'].shift()\n",
    "        # Flag changes or missing answers\n",
    "        flags = (group['Answer'] != shifted) | group['Answer'].isna()\n",
    "        # Explicitly set the first entry to True if it is NaN\n",
    "        if group['Answer'].isna().iloc[0]:\n",
    "            flags.iloc[0] = True\n",
    "        else:\n",
    "            flags.iloc[0] = False\n",
    "        return flags.astype(int)\n",
    "\n",
    "    # Apply the flagging function to each group\n",
    "    df['Flag'] = df.groupby(['Facility_ID', 'Indicator_Name'], as_index=False, group_keys=False).apply(flag_changes_with_initial_check)\n",
    "\n",
    "    # Initialize new columns for structured results\n",
    "    df['Detection_Result'] = pd.NA\n",
    "    df['Detection_Details'] = pd.NA\n",
    "\n",
    "    # Update detection result and details based on flags\n",
    "    for name, group in df.groupby(['Facility_ID', 'Indicator_Name']):\n",
    "        changes = group.index[group['Flag'] == 1]\n",
    "\n",
    "        for idx in changes:\n",
    "            facility_id = df.at[idx, 'Facility_ID']\n",
    "            indicator_name = df.at[idx, 'Indicator_Name']\n",
    "            reporting_period = df.at[idx, 'Reporting_Period'].strftime('%m/%d/%Y')\n",
    "\n",
    "            # Correctly find the previous reporting period\n",
    "            prev_idx = group.index.get_loc(idx) - 1\n",
    "            \n",
    "            if prev_idx >= 0:\n",
    "                previous_reporting_period = group['Reporting_Period'].iloc[prev_idx].strftime('%m/%d/%Y')\n",
    "                previous_answer = group['Answer'].iloc[prev_idx]\n",
    "            else:\n",
    "                previous_reporting_period = \"N/A\"\n",
    "                previous_answer = None\n",
    "\n",
    "            if pd.isna(df.at[idx, 'Answer']):\n",
    "                df.at[idx, 'Detection_Result'] = \"Missing Answer\"\n",
    "                df.at[idx, 'Detection_Details'] = f\"Anomaly Detected On: {reporting_period}\"\n",
    "            else:\n",
    "                if prev_idx >= 0:\n",
    "                    new_answer = df.at[idx, 'Answer']\n",
    "                    df.at[idx, 'Detection_Result'] = \"Answer Changed\"\n",
    "                    df.at[idx, 'Detection_Details'] = (\n",
    "                        f\"Answer Changed From: {previous_answer} to {new_answer}\\n\"\n",
    "                        f\"Between: {previous_reporting_period} and {reporting_period}\"\n",
    "                    )\n",
    "\n",
    "    # Create the flagged dataset with the specified columns\n",
    "    flagged_df = df[df['Flag'] == 1][[\n",
    "        'BUNAME_BU', 'Reporting_Period', 'Facility_ID', 'FACILITY_NAME', \n",
    "        'Indicator_Name', 'BTLR_NAME_ISSCOM', 'Detection_Result', 'Detection_Details'\n",
    "    ]]\n",
    "\n",
    "    # List of cleaned BUNAME values to iterate over\n",
    "    buname_values = df['BUNAME_BU'].unique()\n",
    "\n",
    "    # Create datasets for each BUNAME\n",
    "    datasets = {}\n",
    "    for buname in buname_values:\n",
    "        bu_full_df = df[df['BUNAME_BU'] == buname]\n",
    "        bu_flagged_df = flagged_df[flagged_df['BUNAME_BU'] == buname]\n",
    "        \n",
    "        datasets[f\"{buname}_full_dataset\"] = bu_full_df\n",
    "        datasets[f\"{buname}_flagged_dataset\"] = bu_flagged_df\n",
    "\n",
    "    return df, flagged_df, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69e50cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_datasets_to_csv(datasets, flagged_df):\n",
    "    # Save each flagged dataset to CSV files\n",
    "    for key in datasets:\n",
    "        if \"flagged_dataset\" in key:\n",
    "            bu_name = key.split(\"_\")[0]\n",
    "            flagged_filename = f\"{bu_name}_task1_flagged.csv\"\n",
    "            bu_flagged_df = datasets[key]\n",
    "            bu_flagged_df.to_csv(flagged_filename, index=False)\n",
    "\n",
    "    # Save complete flagged DataFrame containing entries from all BUs\n",
    "    complete_flagged_filename = \"all_OUs_task1_flagged.csv\"\n",
    "    flagged_df.to_csv(complete_flagged_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21d42cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset, flagged_dataset, separate_datasets = detect_changes(text_input_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36419ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_datasets_to_csv(separate_datasets, flagged_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8573a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### This function processes a DataFrame to identify anomalies or changes in answers within \n",
    "# specific groups based on Facility_ID and Indicator_Name over time. It operates on \n",
    "# columns such as BUNAME_BU, Reporting_Period, and Answer, updating the DataFrame to \n",
    "# add flags for anomalies and detailed detection results.\n",
    "\n",
    "\n",
    "# def detect_changes(df):\n",
    "    \n",
    "#     # Remove suffix \"BU\" from BUNAME_BU values\n",
    "#     df['BUNAME_BU'] = df['BUNAME_BU'].str.replace(r'\\s*BU$', '', regex=True)\n",
    "    \n",
    "#     # Ensure 'Reporting_Period' is a datetime object for sorting\n",
    "#     df['Reporting_Period'] = pd.to_datetime(df['Reporting_Period'], format='%m/%d/%Y')\n",
    "\n",
    "#     # Sort the DataFrame by 'Facility_ID', 'Indicator_Name', and 'Reporting_Period'\n",
    "#     df.sort_values(by=['Facility_ID', 'Indicator_Name', 'Reporting_Period'], inplace=True)\n",
    "\n",
    "#     # Initialize 'Flag' column with default value 0\n",
    "#     df['Flag'] = 0\n",
    "    \n",
    "#     # Define a function to flag changes and missing answers\n",
    "#     def flag_changes_with_initial_check(group):\n",
    "#         shifted = group['Answer'].shift()\n",
    "#         # Flag changes or missing answers\n",
    "#         flags = (group['Answer'] != shifted) | group['Answer'].isna()\n",
    "#         # Explicitly set the first entry to True if it is NaN\n",
    "#         if group['Answer'].isna().iloc[0]:\n",
    "#             flags.iloc[0] = True\n",
    "#         else:\n",
    "#             flags.iloc[0] = False\n",
    "#         return flags.astype(int)\n",
    "\n",
    "#     # Apply the flagging function to each group\n",
    "#     df['Flag'] = df.groupby(['Facility_ID', 'Indicator_Name'], as_index=False, group_keys=False).apply(flag_changes_with_initial_check)\n",
    "\n",
    "#     # Initialize new columns for structured results\n",
    "#     df['Detection_Result'] = pd.NA\n",
    "#     df['Detection_Details'] = pd.NA\n",
    "\n",
    "#     # Update detection result and details based on flags\n",
    "#     for name, group in df.groupby(['Facility_ID', 'Indicator_Name']):\n",
    "#         changes = group.index[group['Flag'] == 1]\n",
    "\n",
    "#         for idx in changes:\n",
    "#             facility_id = df.at[idx, 'Facility_ID']\n",
    "#             indicator_name = df.at[idx, 'Indicator_Name']\n",
    "#             reporting_period = df.at[idx, 'Reporting_Period'].strftime('%m/%d/%Y')\n",
    "\n",
    "#             # Correctly find the previous reporting period\n",
    "#             prev_idx = group.index.get_loc(idx) - 1\n",
    "            \n",
    "#             if prev_idx >= 0:\n",
    "#                 previous_reporting_period = group['Reporting_Period'].iloc[prev_idx].strftime('%m/%d/%Y')\n",
    "#                 previous_answer = group['Answer'].iloc[prev_idx]\n",
    "#             else:\n",
    "#                 previous_reporting_period = \"N/A\"\n",
    "#                 previous_answer = None\n",
    "\n",
    "#             if pd.isna(df.at[idx, 'Answer']):\n",
    "#                 df.at[idx, 'Detection_Result'] = \"Missing Answer\"\n",
    "#                 df.at[idx, 'Detection_Details'] = f\"Anomaly Detected On: {reporting_period}\"\n",
    "#             else:\n",
    "#                 if prev_idx >= 0:\n",
    "#                     new_answer = df.at[idx, 'Answer']\n",
    "#                     df.at[idx, 'Detection_Result'] = \"Answer Changed\"\n",
    "#                     df.at[idx, 'Detection_Details'] = (\n",
    "#                         f\"Answer Changed From: {previous_answer} to {new_answer}\\n\"\n",
    "#                         f\"Between: {previous_reporting_period} and {reporting_period}\"\n",
    "#                     )\n",
    "\n",
    "#     # Create the flagged dataset with the specified columns\n",
    "#     flagged_df = df[df['Flag'] == 1][[\n",
    "#         'BUNAME_BU', 'Reporting_Period', 'Facility_ID', 'FACILITY_NAME', \n",
    "#         'Indicator_Name', 'BTLR_NAME_ISSCOM', 'Detection_Result', 'Detection_Details'\n",
    "#     ]]\n",
    "\n",
    "#     return df, flagged_df\n",
    "\n",
    "# # Example usage\n",
    "# full_dataset, flagged_dataset = detect_changes(text_input_ind)\n",
    "# display(full_dataset.head())\n",
    "# display(flagged_dataset.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecasting_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
